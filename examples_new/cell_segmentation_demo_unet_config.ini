# This is a configuration template for a CLASSIFICATION (segmentation) study.
[settings]

# Trainer mode: one of `train`, `resume`, `predict`
trainer_mode = train

# Root project directory
project_dir = ${HOME}/Documents/qute/data/

# Root of data directory: either absolute path, or relative to `project_dir`
data_dir = demo_segmentation_3_classes

# Subfolder for the source images for training/validation/testing
source_images_sub_folder = images

# Subfolder for the target images for training/validation/testing
target_images_sub_folder = labels

# Label for the source images for training/validation/testing
source_images_label = image

# Label for the target images for training/validation/testing
target_images_label = label

# Number of input channels (e.g., 1 for a gray-scale image)
in_channels = 1

# Number of output channels (corresponds to the number of classes to predict)
out_channels = 3

# Fraction of source images to be used for training (0.0 - 1.0): omit for default
train_fraction = 0.7

# Fraction of source images to be used for validation (0.0 - 1.0): omit for default
val_fraction = 0.2

# Fraction of source images to be used for testing (0.0 - 1.0): omit for default
test_fraction = 0.1

# Full path to the images to be used for prediction: must be specified if trainer_mode is `predict`
source_for_prediction = ${HOME}/Documents/qute/data/demo_segmentation_3_classes/images

# Full path to the folder where the predicted images will be stored: omit for default target
target_for_prediction =

# Whether to start from a self-supervised model
fine_tune_from_self_supervised = False

# Full path to an existing model for `resume` or `predict`: ignored if trainer_mode is `train`
source_model_path =

# Seed for random number generation initialization
seed = 2022

# Batch size for training
batch_size = 8

# Batch size for interference
inference_batch_size = 4

# Number of patches per image: total batch size will be `batch_size` * `num_patches`
num_patches = 1

# Number of residual units for the U-Net
num_res_units = 4

# Number of layers and corresponding filters in the U-Net encoder (contracting path)
channels = 16, 32, 64

# Kernel strides: must be one entry shorter than `channels` (omit to use defaults)
strides = 2, 2

# Size of one patch
patch_size = 640, 640

# Initial learning rate
learning_rate = 0.001

# Whether the background class should be included in the calculation of loss and metrics
include_background = True

# Class names (for logs and TensorBoard)
class_names =  background, cell, membrane

# Maximum number of training epochs
max_epochs = 3

# Precision used by PyTorch for calculations
precision = 16-mixed
