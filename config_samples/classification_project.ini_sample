# This is a configuration template for a CLASSIFICATION (segmentation) study.
[settings]

# Model class (one of unet, attention_unet, swin_unetr)
model_class = unet

# Trainer mode: one of `train`, `resume`, `predict`
trainer_mode = train

# Root project directory
project_dir = /path/to/project

# Root of data directory: either absolute path, or relative to `project_dir`
data_dir = ground_truth

# Subfolder for the source images for training/validation/testing
source_images_sub_folder = images

# Subfolder for the target images for training/validation/testing
target_images_sub_folder = labels

# Label for the source images for training/validation/testing
source_images_label = image

# Label for the target images for training/validation/testing
target_images_label = label

# Number of input channels (e.g., 1 for a gray-scale image)
in_channels = 1

# Number of output channels (corresponds to the number of classes to predict)
out_channels = 3

# Fraction of source images to be used for training (0.0 - 1.0): omit for default
train_fraction = 0.7

# Fraction of source images to be used for validation (0.0 - 1.0): omit for default
val_fraction = 0.2

# Fraction of source images to be used for testing (0.0 - 1.0): omit for default
test_fraction = 0.1

# Checkpoint monitor: one of "loss" or "metrics"
checkpoint_monitor = loss

# Checkpoint metrics class: if `checkpoint_target` is `metrics`, one of the classes from `class_names`
# can be used as monitor. Leave unset to use the global validation metric.
# Ignored if `checkpoint_target` is loss.
checkpoint_metrics_class =

# Use early stopping based on `checkpoint_monitor` and `checkpoint_metrics_class`?
use_early_stopping = True
early_stopping_patience = 10

# Full path to the images to be used for prediction: must be specified if trainer_mode is `predict`
source_for_prediction = 

# Full path to the folder where the predicted images will be stored: omit for default target
target_for_prediction =

# Full path to an existing model for `resume` or `predict`: ignored if trainer_mode is `train`
source_model_path =

# Seed for random number generation initialization
seed = 2022

# Batch size for training
batch_size = 8

# Batch size for interference
inference_batch_size = 4

# Number of patches per image: total batch size will be `batch_size` * `num_patches`
num_patches = 1

# Number of residual units for the U-Net
num_res_units = 4

# [unet, attenuation_net] Number of layers and corresponding filters in the U-Net encoder (contracting path)
channels = 16, 32, 64

# [unet, attenuation_net] Kernel strides: must be one entry shorter than `channels` (omit to use defaults)
strides = 2, 2

# [swin_unetr] Number of layers in each stage
depths = 2, 2, 2, 2

# [swin_unetr] Number of attention heads
num_heads = 3, 6, 12, 24

# [swin_unetr] Dimension of network feature size
feature_size = 24

# Size of one patch
patch_size = 640, 640

# Initial learning rate
learning_rate = 0.001

# Whether the background class should be included in the calculation of loss and metrics
include_background = True

# Class names (for logs and TensorBoard)
class_names =  background, cell, membrane

# Maximum number of training epochs
max_epochs = 2000

# Precision used by PyTorch for calculations
precision = 16-mixed
